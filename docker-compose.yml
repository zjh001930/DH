version: '3.8'

services:
  # PostgreSQL 数据库
  postgres:
    image: postgres:13
    container_name: ai_assistant_postgres
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ai_assistant}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      LC_ALL: C.UTF-8
      LANG: C.UTF-8
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Ollama 服务
  # 1. Ollama 服务 (LLM 和 Embedding)
  ollama_service:
    image: ollama/ollama:latest
    container_name: ollama_host
    env_file:
      - .env
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_models:/root/.ollama
    # 移除自定义命令，让容器使用默认启动方式
    restart: always

  # Weaviate 向量数据库
  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: ai_assistant_weaviate
    env_file:
      - .env
    ports:
      - "${WEAVIATE_PORT:-8080}:8080"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_APIKEY_ENABLED: 'false'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: ''
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: always
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=3", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 90s

  # 后端服务
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.backend
    container_name: ai_assistant_backend
    env_file:
      - .env
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:password@postgres:5432/ai_assistant}
      OLLAMA_API_URL: ${OLLAMA_API_URL:-http://ollama_service:11434}
      WEAVIATE_HOST: ${WEAVIATE_HOST:-weaviate:8080}
      LLM_MODEL_NAME: ${LLM_MODEL_NAME:-qwen2.5:3b-instruct}
      EMBEDDING_MODEL_NAME: ${EMBEDDING_MODEL_NAME:-bge-m3}
      INTENT_CONFIDENCE_THRESHOLD: ${INTENT_CONFIDENCE_THRESHOLD:-0.75}
      IMAGE_STORAGE_PATH: ${IMAGE_STORAGE_PATH:-/app/data/images}
      FLASK_ENV: ${FLASK_ENV:-production}
      FLASK_DEBUG: ${FLASK_DEBUG:-0}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
      ollama_service:
        condition: service_started
      weaviate:
        condition: service_started
    volumes:
      - ./backend:/app

  # 前端服务
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.frontend
    container_name: ai_assistant_frontend
    env_file:
      - .env
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    environment:
      REACT_APP_BACKEND_URL: ${REACT_APP_BACKEND_URL:-http://localhost:8000}
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules

# 定义持久化存储卷
volumes:
  postgres_data:
    driver: local
  ollama_models:
    driver: local
  weaviate_data:
    driver: local